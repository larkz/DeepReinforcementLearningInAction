{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\r\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0 513.9256591796875\n",
      "2\n",
      "0 549.933837890625\n",
      "0\n",
      "0 1293.608642578125\n",
      "2\n",
      "0 1245.2554931640625\n",
      "0\n",
      "0 604.03369140625\n",
      "1\n",
      "0 672.3389282226562\n",
      "1\n",
      "0 637.406005859375\n",
      "2\n",
      "0 1007.72314453125\n",
      "0\n",
      "0 1332.7237548828125\n",
      "1\n",
      "0 762.873779296875\n",
      "0\n",
      "0 773.4631958007812\n",
      "0\n",
      "0 753.47314453125\n",
      "2\n",
      "0 839.9435424804688\n",
      "2\n",
      "0 805.9043579101562\n",
      "2\n",
      "0 835.4029541015625\n",
      "2\n",
      "0 643.6495971679688\n",
      "1\n",
      "0 1048.369140625\n",
      "1\n",
      "0 457.4663391113281\n",
      "0\n",
      "0 899.265869140625\n",
      "2\n",
      "0 901.38818359375\n",
      "3\n",
      "0 659.257080078125\n",
      "0\n",
      "0 650.5118408203125\n",
      "3\n",
      "0 596.4720458984375\n",
      "0\n",
      "0 544.3685302734375\n",
      "0\n",
      "0 1510.3271484375\n",
      "3\n",
      "0 676.796875\n",
      "0\n",
      "0 675.6795043945312\n",
      "2\n",
      "0 471.1875915527344\n",
      "1\n",
      "0 726.968505859375\n",
      "1\n",
      "0 591.016845703125\n",
      "1\n",
      "0 822.8739013671875\n",
      "1\n",
      "0 326.73455810546875\n",
      "2\n",
      "0 802.9874877929688\n",
      "1\n",
      "0 966.1038818359375\n",
      "3\n",
      "0 741.1837768554688\n",
      "1\n",
      "0 1243.6767578125\n",
      "2\n",
      "0 1007.0546875\n",
      "1\n",
      "0 851.9765014648438\n",
      "2\n",
      "0 993.968505859375\n",
      "2\n",
      "0 985.7945556640625\n",
      "3\n",
      "0 654.112548828125\n",
      "1\n",
      "0 828.2047119140625\n",
      "1\n",
      "0 1223.1298828125\n",
      "2\n",
      "0 951.9774169921875\n",
      "3\n",
      "0 827.6835327148438\n",
      "1\n",
      "0 721.1034545898438\n",
      "3\n",
      "0 436.3843688964844\n",
      "2\n",
      "0 820.635986328125\n",
      "2\n",
      "0 1309.4139404296875\n",
      "2\n",
      "0 1051.9078369140625\n",
      "2\n",
      "0 663.8681030273438\n",
      "2\n",
      "1 654.9113159179688\n",
      "3\n",
      "1 536.0885009765625\n",
      "0\n",
      "1 815.0914306640625\n",
      "3\n",
      "1 824.10546875\n",
      "0\n",
      "1 504.1992492675781\n",
      "1\n",
      "1 499.5819091796875\n",
      "2\n",
      "1 647.1970825195312\n",
      "2\n",
      "1 685.7205200195312\n",
      "1\n",
      "1 577.45361328125\n",
      "1\n",
      "1 883.2421264648438\n",
      "0\n",
      "1 1178.6312255859375\n",
      "2\n",
      "1 705.1885375976562\n",
      "2\n",
      "1 949.7242431640625\n",
      "1\n",
      "1 636.6851196289062\n",
      "3\n",
      "1 536.7500610351562\n",
      "0\n",
      "1 724.5630493164062\n",
      "3\n",
      "1 1138.335205078125\n",
      "1\n",
      "1 641.1986694335938\n",
      "2\n",
      "1 695.7281494140625\n",
      "2\n",
      "1 698.8909301757812\n",
      "0\n",
      "1 626.46044921875\n",
      "1\n",
      "1 627.6043701171875\n",
      "2\n",
      "1 637.6451416015625\n",
      "0\n",
      "1 820.9037475585938\n",
      "3\n",
      "1 771.7151489257812\n",
      "0\n",
      "1 631.3306884765625\n",
      "3\n",
      "1 912.1058349609375\n",
      "0\n",
      "1 594.2854614257812\n",
      "1\n",
      "1 756.48828125\n",
      "1\n",
      "1 791.4236450195312\n",
      "1\n",
      "1 524.5616455078125\n",
      "0\n",
      "1 816.1325073242188\n",
      "1\n",
      "1 818.10107421875\n",
      "3\n",
      "1 850.63916015625\n",
      "0\n",
      "1 688.6797485351562\n",
      "2\n",
      "1 965.2254028320312\n",
      "2\n",
      "1 378.9261779785156\n",
      "1\n",
      "1 597.3927612304688\n",
      "2\n",
      "1 410.07928466796875\n",
      "2\n",
      "1 370.2040710449219\n",
      "3\n",
      "1 932.1746215820312\n",
      "3\n",
      "1 755.1207275390625\n",
      "2\n",
      "1 542.300537109375\n",
      "2\n",
      "1 825.4628295898438\n",
      "2\n",
      "1 737.7149047851562\n",
      "3\n",
      "1 735.5380249023438\n",
      "0\n",
      "1 750.91064453125\n",
      "2\n",
      "1 522.7449340820312\n",
      "0\n",
      "1 730.0603637695312\n",
      "1\n",
      "1 692.44287109375\n",
      "0\n",
      "1 591.8551635742188\n",
      "3\n",
      "2 832.9573364257812\n",
      "2\n",
      "2 846.06640625\n",
      "0\n",
      "2 618.3128051757812\n",
      "0\n",
      "2 413.5874328613281\n",
      "3\n",
      "2 766.9188842773438\n",
      "3\n",
      "2 632.5195922851562\n",
      "3\n",
      "2 1221.5068359375\n",
      "2\n",
      "2 649.6378173828125\n",
      "2\n",
      "2 1169.66357421875\n",
      "1\n",
      "2 679.7217407226562\n",
      "0\n",
      "2 710.2029418945312\n",
      "0\n",
      "2 858.3392944335938\n",
      "0\n",
      "2 784.7572631835938\n",
      "2\n",
      "2 535.943115234375\n",
      "0\n",
      "2 801.6439819335938\n",
      "0\n",
      "2 859.6124877929688\n",
      "0\n",
      "2 564.2485961914062\n",
      "1\n",
      "2 747.8253784179688\n",
      "1\n",
      "2 942.1481323242188\n",
      "1\n",
      "2 504.6390686035156\n",
      "2\n",
      "2 530.353271484375\n",
      "1\n",
      "2 904.4617309570312\n",
      "1\n",
      "2 412.5394592285156\n",
      "3\n",
      "2 666.0346069335938\n",
      "3\n",
      "2 522.665771484375\n",
      "1\n",
      "2 904.4767456054688\n",
      "3\n",
      "2 417.2529602050781\n",
      "3\n",
      "2 484.2100830078125\n",
      "0\n",
      "2 652.6387329101562\n",
      "3\n",
      "2 836.8666381835938\n",
      "2\n",
      "2 638.0218505859375\n",
      "2\n",
      "2 772.9188842773438\n",
      "2\n",
      "2 848.693359375\n",
      "1\n",
      "2 966.9541625976562\n",
      "1\n",
      "2 321.7840270996094\n",
      "0\n",
      "2 982.6878051757812\n",
      "0\n",
      "2 865.2935791015625\n",
      "0\n",
      "2 1176.22314453125\n",
      "2\n",
      "2 1008.5511474609375\n",
      "3\n",
      "2 300.54168701171875\n",
      "3\n",
      "2 739.7404174804688\n",
      "1\n",
      "2 961.392822265625\n",
      "3\n",
      "2 669.2522583007812\n",
      "2\n",
      "2 836.9346923828125\n",
      "2\n",
      "2 724.8054809570312\n",
      "2\n",
      "2 5950.830078125\n",
      "3\n",
      "2 645.3473510742188\n",
      "3\n",
      "2 979.24072265625\n",
      "3\n",
      "2 755.390380859375\n",
      "1\n",
      "2 627.7042846679688\n",
      "1\n",
      "2 606.7950439453125\n",
      "1\n",
      "3 490.10272216796875\n",
      "1\n",
      "3 485.52081298828125\n",
      "1\n",
      "3 922.9183349609375\n",
      "1\n",
      "3 760.458740234375\n",
      "1\n",
      "3 5909.45556640625\n",
      "2\n",
      "3 561.7699584960938\n",
      "1\n",
      "3 883.1989135742188\n",
      "3\n",
      "3 537.2564697265625\n",
      "3\n",
      "3 699.4216918945312\n",
      "3\n",
      "3 955.134765625\n",
      "2\n",
      "3 405.50140380859375\n",
      "3\n",
      "3 1027.79541015625\n",
      "1\n",
      "3 452.0764465332031\n",
      "2\n",
      "3 765.968017578125\n",
      "3\n",
      "3 777.616455078125\n",
      "0\n",
      "3 639.123291015625\n",
      "0\n",
      "3 605.8035278320312\n",
      "1\n",
      "3 833.92236328125\n",
      "3\n",
      "3 741.5270385742188\n",
      "3\n",
      "3 767.7957153320312\n",
      "3\n",
      "3 514.7482299804688\n",
      "0\n",
      "3 758.3548583984375\n",
      "3\n",
      "3 863.8180541992188\n",
      "3\n",
      "3 6085.798828125\n",
      "0\n",
      "3 796.8722534179688\n",
      "0\n",
      "3 527.3410034179688\n",
      "2\n",
      "3 686.1669311523438\n",
      "3\n",
      "3 989.6734619140625\n",
      "2\n",
      "3 6200.064453125\n",
      "3\n",
      "3 477.5072937011719\n",
      "3\n",
      "3 596.3953857421875\n",
      "2\n",
      "3 972.442626953125\n",
      "3\n",
      "3 772.5234375\n",
      "3\n",
      "3 584.7058715820312\n",
      "0\n",
      "3 662.4838256835938\n",
      "1\n",
      "3 947.4088134765625\n",
      "3\n",
      "3 519.6267700195312\n",
      "0\n",
      "3 877.1593627929688\n",
      "2\n",
      "3 775.1029663085938\n",
      "0\n",
      "3 673.9744262695312\n",
      "1\n",
      "3 1099.3045654296875\n",
      "1\n",
      "3 5866.76416015625\n",
      "1\n",
      "3 615.6112060546875\n",
      "2\n",
      "3 1007.2734375\n",
      "1\n",
      "3 466.63641357421875\n",
      "0\n",
      "3 1457.692626953125\n",
      "1\n",
      "3 979.1361083984375\n",
      "2\n",
      "3 870.1665649414062\n",
      "3\n",
      "3 746.668701171875\n",
      "1\n",
      "3 824.2588500976562\n",
      "3\n",
      "3 586.4078979492188\n",
      "3\n",
      "4 964.2059936523438\n",
      "0\n",
      "4 944.5184936523438\n",
      "2\n",
      "4 908.973876953125\n",
      "2\n",
      "4 922.8279418945312\n",
      "2\n",
      "4 1117.118408203125\n",
      "1\n",
      "4 775.0455322265625\n",
      "0\n",
      "4 581.2385864257812\n",
      "3\n",
      "4 732.744384765625\n",
      "1\n",
      "4 768.0856323242188\n",
      "0\n",
      "4 677.8824462890625\n",
      "3\n",
      "4 975.5435791015625\n",
      "2\n",
      "4 945.6099853515625\n",
      "0\n",
      "4 942.562744140625\n",
      "0\n",
      "4 627.27099609375\n",
      "0\n",
      "4 662.6800537109375\n",
      "0\n",
      "4 714.83447265625\n",
      "3\n",
      "4 667.5953979492188\n",
      "2\n",
      "4 895.683349609375\n",
      "0\n",
      "4 604.3771362304688\n",
      "0\n",
      "4 705.6172485351562\n",
      "0\n",
      "4 490.5879821777344\n",
      "1\n",
      "4 1002.38427734375\n",
      "1\n",
      "4 746.7882690429688\n",
      "2\n",
      "4 565.66943359375\n",
      "2\n",
      "4 820.6849975585938\n",
      "2\n",
      "4 1110.9599609375\n",
      "2\n",
      "4 1023.0789184570312\n",
      "1\n",
      "4 750.6111450195312\n",
      "1\n",
      "4 873.8245849609375\n",
      "1\n",
      "4 618.9309692382812\n",
      "2\n",
      "4 530.2658081054688\n",
      "1\n",
      "4 799.7784423828125\n",
      "1\n",
      "4 978.2728271484375\n",
      "0\n",
      "4 646.2160034179688\n",
      "1\n",
      "4 434.7848815917969\n",
      "3\n",
      "4 912.5752563476562\n",
      "1\n",
      "4 600.4881591796875\n",
      "1\n",
      "4 646.2990112304688\n",
      "2\n",
      "4 551.3151245117188\n",
      "3\n",
      "4 837.5390625\n",
      "2\n",
      "4 5989.2080078125\n",
      "1\n",
      "4 892.7198486328125\n",
      "3\n",
      "4 705.68798828125\n",
      "0\n",
      "4 624.1475219726562\n",
      "0\n",
      "4 317.69976806640625\n",
      "2\n",
      "4 870.9226684570312\n",
      "2\n",
      "4 905.6571655273438\n",
      "0\n",
      "4 616.2003784179688\n",
      "1\n",
      "4 377.5428466796875\n",
      "3\n",
      "4 478.4757080078125\n",
      "3\n",
      "4 378.2641906738281\n",
      "0\n",
      "5 559.134033203125\n",
      "1\n",
      "5 1088.79736328125\n",
      "1\n",
      "5 843.937744140625\n",
      "3\n",
      "5 598.6890869140625\n",
      "0\n",
      "5 1033.9111328125\n",
      "3\n",
      "5 523.4998168945312\n",
      "1\n",
      "5 610.7423706054688\n",
      "1\n",
      "5 428.0224304199219\n",
      "3\n",
      "5 571.9758911132812\n",
      "0\n",
      "5 935.3373413085938\n",
      "3\n",
      "5 5907.14111328125\n",
      "2\n",
      "5 398.2903137207031\n",
      "3\n",
      "5 489.5321044921875\n",
      "0\n",
      "5 709.341796875\n",
      "1\n",
      "5 487.3123474121094\n",
      "3\n",
      "5 611.7567138671875\n",
      "0\n",
      "5 812.2586059570312\n",
      "3\n",
      "5 847.1453857421875\n",
      "0\n",
      "5 695.9241333007812\n",
      "2\n",
      "5 665.724365234375\n",
      "2\n",
      "5 530.7191162109375\n",
      "1\n",
      "5 737.1071166992188\n",
      "3\n",
      "5 625.9808349609375\n",
      "0\n",
      "5 546.7402954101562\n",
      "3\n",
      "5 878.2301635742188\n",
      "0\n",
      "5 1123.2750244140625\n",
      "3\n",
      "5 800.5093994140625\n",
      "1\n",
      "5 867.526123046875\n",
      "2\n",
      "5 603.2740478515625\n",
      "2\n",
      "5 753.8975830078125\n",
      "2\n",
      "5 978.1634521484375\n",
      "3\n",
      "5 615.295654296875\n",
      "1\n",
      "5 1297.083251953125\n",
      "1\n",
      "5 468.015380859375\n",
      "3\n",
      "5 861.7969360351562\n",
      "1\n",
      "5 650.2627563476562\n",
      "1\n",
      "5 470.4374084472656\n",
      "1\n",
      "5 471.17706298828125\n",
      "2\n",
      "5 766.6744384765625\n",
      "0\n",
      "5 652.1284790039062\n",
      "2\n",
      "5 818.4742431640625\n",
      "2\n",
      "5 657.047119140625\n",
      "1\n",
      "5 878.49853515625\n",
      "1\n",
      "5 1189.3115234375\n",
      "2\n",
      "5 684.28466796875\n",
      "0\n",
      "5 342.433349609375\n",
      "3\n",
      "5 776.2361450195312\n",
      "2\n",
      "5 720.893310546875\n",
      "3\n",
      "5 872.0507202148438\n",
      "3\n",
      "5 1002.702880859375\n",
      "0\n",
      "5 561.9231567382812\n",
      "0\n",
      "6 608.9849853515625\n",
      "2\n",
      "6 748.9816284179688\n",
      "1\n",
      "6 926.0214233398438\n",
      "1\n",
      "6 553.693603515625\n",
      "2\n",
      "6 640.8142700195312\n",
      "3\n",
      "6 874.82470703125\n",
      "2\n",
      "6 787.790771484375\n",
      "3\n",
      "6 763.8524780273438\n",
      "0\n",
      "6 650.7664184570312\n",
      "3\n",
      "6 637.0960693359375\n",
      "2\n",
      "6 518.9925537109375\n",
      "1\n",
      "6 352.2822265625\n",
      "3\n",
      "6 897.0218505859375\n",
      "2\n",
      "6 733.8570556640625\n",
      "2\n",
      "6 675.9204711914062\n",
      "0\n",
      "6 715.249267578125\n",
      "3\n",
      "6 445.84002685546875\n",
      "2\n",
      "6 596.084716796875\n",
      "2\n",
      "6 316.8788146972656\n",
      "1\n",
      "6 393.5381164550781\n",
      "2\n",
      "6 511.0904541015625\n",
      "1\n",
      "6 656.1275634765625\n",
      "2\n",
      "6 550.103759765625\n",
      "0\n",
      "6 840.9888305664062\n",
      "0\n",
      "6 5920.87939453125\n",
      "2\n",
      "6 944.7513427734375\n",
      "0\n",
      "6 879.3789672851562\n",
      "0\n",
      "6 1087.093017578125\n",
      "0\n",
      "6 702.9501342773438\n",
      "2\n",
      "6 813.6679077148438\n",
      "3\n",
      "6 812.9681396484375\n",
      "3\n",
      "6 5939.03857421875\n",
      "0\n",
      "6 476.8520202636719\n",
      "2\n",
      "6 711.9065551757812\n",
      "1\n",
      "6 798.8203125\n",
      "0\n",
      "6 1556.845947265625\n",
      "1\n",
      "6 856.7901000976562\n",
      "3\n",
      "6 556.6455688476562\n",
      "2\n",
      "6 678.7369384765625\n",
      "3\n",
      "6 682.9415893554688\n",
      "0\n",
      "6 387.3039855957031\n",
      "2\n",
      "6 5950.28271484375\n",
      "3\n",
      "6 503.8720703125\n",
      "0\n",
      "6 619.3312377929688\n",
      "2\n",
      "6 446.2221984863281\n",
      "1\n",
      "6 5727.38134765625\n",
      "3\n",
      "6 762.583740234375\n",
      "3\n",
      "6 824.6384887695312\n",
      "0\n",
      "6 501.2738342285156\n",
      "2\n",
      "6 866.8079833984375\n",
      "3\n",
      "6 6203.779296875\n",
      "3\n",
      "7 778.5702514648438\n",
      "2\n",
      "7 500.88787841796875\n",
      "1\n",
      "7 481.62225341796875\n",
      "0\n",
      "7 527.3949584960938\n",
      "1\n",
      "7 879.185302734375\n",
      "2\n",
      "7 404.19403076171875\n",
      "0\n",
      "7 696.390380859375\n",
      "1\n",
      "7 623.267578125\n",
      "2\n",
      "7 483.1213684082031\n",
      "1\n",
      "7 513.2796630859375\n",
      "3\n",
      "7 799.6904907226562\n",
      "1\n",
      "7 677.8640747070312\n",
      "2\n",
      "7 709.9646606445312\n",
      "3\n",
      "7 491.2835998535156\n",
      "1\n",
      "7 503.5323181152344\n",
      "1\n",
      "7 584.1679077148438\n",
      "2\n",
      "7 564.4879150390625\n",
      "0\n",
      "7 1083.99560546875\n",
      "0\n",
      "7 869.535400390625\n",
      "3\n",
      "7 479.228759765625\n",
      "0\n",
      "7 477.15948486328125\n",
      "1\n",
      "7 797.0667114257812\n",
      "1\n",
      "7 985.9885864257812\n",
      "1\n",
      "7 525.9240112304688\n",
      "3\n",
      "7 646.8301391601562\n",
      "1\n",
      "7 658.939453125\n",
      "3\n",
      "7 506.90985107421875\n",
      "3\n",
      "7 900.96923828125\n",
      "0\n",
      "7 565.3250122070312\n",
      "2\n",
      "7 467.28839111328125\n",
      "3\n",
      "7 944.6253051757812\n",
      "3\n",
      "7 480.8593444824219\n",
      "0\n",
      "7 775.7568969726562\n",
      "3\n",
      "7 653.919189453125\n",
      "1\n",
      "7 552.5769653320312\n",
      "2\n",
      "7 369.8464050292969\n",
      "1\n",
      "7 634.934326171875\n",
      "0\n",
      "7 906.9197387695312\n",
      "0\n",
      "7 542.2877197265625\n",
      "0\n",
      "7 955.0719604492188\n",
      "1\n",
      "7 5900.52734375\n",
      "2\n",
      "7 829.1693725585938\n",
      "0\n",
      "7 681.9488525390625\n",
      "2\n",
      "7 596.6068115234375\n",
      "0\n",
      "7 740.7909545898438\n",
      "3\n",
      "7 509.1166687011719\n",
      "2\n",
      "7 687.2681274414062\n",
      "3\n",
      "7 611.1926879882812\n",
      "0\n",
      "7 820.7159423828125\n",
      "3\n",
      "7 590.0614624023438\n",
      "1\n",
      "7 1030.37158203125\n",
      "1\n",
      "8 980.4413452148438\n",
      "0\n",
      "8 778.6915893554688\n",
      "2\n",
      "8 639.1041259765625\n",
      "3\n",
      "8 475.7014465332031\n",
      "3\n",
      "8 720.8967895507812\n",
      "3\n",
      "8 620.2656860351562\n",
      "0\n",
      "8 559.1434936523438\n",
      "1\n",
      "8 767.5643920898438\n",
      "3\n",
      "8 504.5310974121094\n",
      "3\n",
      "8 772.8336791992188\n",
      "2\n",
      "8 326.87738037109375\n",
      "2\n",
      "8 580.1256713867188\n",
      "3\n",
      "8 626.4187622070312\n",
      "3\n",
      "8 458.6366882324219\n",
      "1\n",
      "8 740.2151489257812\n",
      "3\n",
      "8 635.8789672851562\n",
      "3\n",
      "8 659.2408447265625\n",
      "0\n",
      "8 484.2632141113281\n",
      "3\n",
      "8 400.3040771484375\n",
      "1\n",
      "8 400.413818359375\n",
      "3\n",
      "8 516.5556640625\n",
      "1\n",
      "8 5368.62353515625\n",
      "1\n",
      "8 893.8908081054688\n",
      "1\n",
      "8 491.2247619628906\n",
      "1\n",
      "8 663.347412109375\n",
      "2\n",
      "8 881.2184448242188\n",
      "2\n",
      "8 694.355224609375\n",
      "1\n",
      "8 305.0128173828125\n",
      "0\n",
      "8 470.8424072265625\n",
      "0\n",
      "8 419.283447265625\n",
      "0\n",
      "8 627.2648315429688\n",
      "1\n",
      "8 981.9754028320312\n",
      "0\n",
      "8 501.166015625\n",
      "0\n",
      "8 505.35272216796875\n",
      "0\n",
      "8 520.0455322265625\n",
      "2\n",
      "8 5502.72705078125\n",
      "2\n",
      "8 1029.082763671875\n",
      "2\n",
      "8 608.0048217773438\n",
      "3\n",
      "8 5622.18798828125\n",
      "3\n",
      "8 901.1995849609375\n",
      "0\n",
      "8 267.2745056152344\n",
      "2\n",
      "8 556.3043823242188\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_164588/487300938.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# clear_output(wait=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/dqn-marl/.dqn-cpu-env/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/dqn-marl/.dqn-cpu-env/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from environment.Gridworld import Gridworld\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "from matplotlib import pylab as plt\n",
    "from collections import deque\n",
    "from common.test import *\n",
    "from environment.MarketEnv import MarketEnv\n",
    "from agent.properties import *\n",
    "\n",
    "for i in range(epochs):\n",
    "    marketEnv = MarketEnv()\n",
    "    state1_ = marketEnv.reset()\n",
    "\n",
    "    state1 = torch.from_numpy(state1_).float().to(device = devid)\n",
    "    status = 1\n",
    "    mov = 0\n",
    "\n",
    "    while(status == 1): \n",
    "        j+=1\n",
    "        mov += 1\n",
    "        qval = model(state1)\n",
    "        \n",
    "        if not torch.cuda.is_available():\n",
    "            qval_ = qval.data.numpy()\n",
    "        else:\n",
    "            qval_ = qval.data.cpu().numpy()\n",
    "        \n",
    "        if (random.random() < epsilon):\n",
    "            action_ = np.random.randint(0,4)\n",
    "        else:\n",
    "            action_ = np.argmax(qval_)\n",
    "        \n",
    "        action = action_\n",
    "        print(action)\n",
    "        \n",
    "        # Execute action and upate state, and get reward + boolTerminal\n",
    "        marketEnv.step(action)\n",
    "        \n",
    "        # rendered_game_boad_2 = game.board.render_np()\n",
    "        state2_, reward, done, info_dic = marketEnv.step(action)\n",
    "        # state2_ = game.board.render_np().reshape(1,64) + np.random.rand(1,64)/100.0\n",
    "        state2 = torch.from_numpy(state2_).float()\n",
    "\n",
    "        exp =  (state1, action_, reward, state2, done)\n",
    "        replay.append(exp) #H\n",
    "        state1 = state2\n",
    "        \n",
    "        if len(replay) > batch_size:\n",
    "            minibatch = random.sample(replay, batch_size)\n",
    "\n",
    "            # Could be replaced with pytorch gather\n",
    "            state1_batch = torch.cat([s1 for (s1,a,r,s2,d) in minibatch]).view(batch_size, l1).to(device = devid)\n",
    "            action_batch = torch.tensor([a for (s1,a,r,s2,d) in minibatch]).type(torch.FloatTensor).to(device = devid)\n",
    "            reward_batch = torch.tensor([r for (s1,a,r,s2,d) in minibatch]).type(torch.FloatTensor).to(device = devid)\n",
    "            state2_batch = torch.cat([s2 for (s1,a,r,s2,d) in minibatch]).view(batch_size, l1).to(device = devid)\n",
    "            done_batch = torch.tensor([d for (s1,a,r,s2,d) in minibatch]).type(torch.FloatTensor).to(device = devid)\n",
    "\n",
    "            # Q update\n",
    "            Q1 = model(state1_batch).to(device = devid)\n",
    "            with torch.no_grad():\n",
    "                Q2 = model2(state2_batch).to(device = devid) #B\n",
    "            \n",
    "            Y = reward_batch + gamma * ((1-done_batch) * torch.max(Q2,dim=1)[0])\n",
    "            X = Q1.gather(dim=1,index=action_batch.long().unsqueeze(dim=1)).squeeze()\n",
    "            loss = loss_fn(X, Y.detach())\n",
    "            print(i, loss.item())\n",
    "            # clear_output(wait=True)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            losses.append(loss.item())\n",
    "            optimizer.step()\n",
    "            \n",
    "            if j % sync_freq == 0: #C\n",
    "                model2.load_state_dict(model.state_dict())\n",
    "        if done or mov > max_moves:\n",
    "            status = 0\n",
    "            mov = 0\n",
    "        \n",
    "losses = np.array(losses)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epochs\",fontsize=22)\n",
    "plt.ylabel(\"Loss\",fontsize=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=150, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=150, out_features=100, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=100, out_features=101, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([2500.0000,   37.6717], device='cuda:0'),\n",
       "  1,\n",
       "  53.0,\n",
       "  tensor([2.4020e+03, 1.0000e+00]),\n",
       "  False),\n",
       " (tensor([2500.0000,   49.7582], device='cuda:0'),\n",
       "  0,\n",
       "  0.0,\n",
       "  tensor([2471.,    0.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   39.1841], device='cuda:0'),\n",
       "  3,\n",
       "  15.0,\n",
       "  tensor([2489.,    3.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   68.1300], device='cuda:0'),\n",
       "  0,\n",
       "  0.0,\n",
       "  tensor([2474.,    0.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   63.9114], device='cuda:0'),\n",
       "  1,\n",
       "  25.0,\n",
       "  tensor([2.4590e+03, 1.0000e+00]),\n",
       "  False),\n",
       " (tensor([2.5000e+03, 1.0197e+00], device='cuda:0'),\n",
       "  3,\n",
       "  33.0,\n",
       "  tensor([2482.,    3.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   73.7868], device='cuda:0'),\n",
       "  3,\n",
       "  81.0,\n",
       "  tensor([2431.,    3.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   45.9809], device='cuda:0'),\n",
       "  2,\n",
       "  48.0,\n",
       "  tensor([2.4450e+03, 2.0000e+00]),\n",
       "  False),\n",
       " (tensor([2500.0000,   70.4715], device='cuda:0'),\n",
       "  0,\n",
       "  0.0,\n",
       "  tensor([2472.,    0.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   60.9973], device='cuda:0'),\n",
       "  3,\n",
       "  90.0,\n",
       "  tensor([2437.,    3.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   13.3981], device='cuda:0'),\n",
       "  2,\n",
       "  40.0,\n",
       "  tensor([2.4630e+03, 2.0000e+00]),\n",
       "  False),\n",
       " (tensor([2500.0000,    7.7266], device='cuda:0'),\n",
       "  3,\n",
       "  87.0,\n",
       "  tensor([2442.,    3.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   70.4940], device='cuda:0'),\n",
       "  1,\n",
       "  4.0,\n",
       "  tensor([2.4920e+03, 1.0000e+00]),\n",
       "  False),\n",
       " (tensor([2.5000e+03, 1.1390e+00], device='cuda:0'),\n",
       "  2,\n",
       "  60.0,\n",
       "  tensor([2.4400e+03, 2.0000e+00]),\n",
       "  False),\n",
       " (tensor([2500.0000,    2.6348], device='cuda:0'),\n",
       "  2,\n",
       "  66.0,\n",
       "  tensor([2.4420e+03, 2.0000e+00]),\n",
       "  False),\n",
       " (tensor([2500.0000,   73.0873], device='cuda:0'),\n",
       "  0,\n",
       "  0.0,\n",
       "  tensor([2412.,    0.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   45.8251], device='cuda:0'),\n",
       "  1,\n",
       "  16.0,\n",
       "  tensor([2.4710e+03, 1.0000e+00]),\n",
       "  False),\n",
       " (tensor([2500.0000,   67.8711], device='cuda:0'),\n",
       "  3,\n",
       "  24.0,\n",
       "  tensor([2490.,    3.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   61.1927], device='cuda:0'),\n",
       "  2,\n",
       "  60.0,\n",
       "  tensor([2.4430e+03, 2.0000e+00]),\n",
       "  False),\n",
       " (tensor([2500.0000,   92.0585], device='cuda:0'),\n",
       "  2,\n",
       "  72.0,\n",
       "  tensor([2.4180e+03, 2.0000e+00]),\n",
       "  False),\n",
       " (tensor([2500.0000,   33.2126], device='cuda:0'),\n",
       "  3,\n",
       "  108.0,\n",
       "  tensor([2427.,    3.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   43.9933], device='cuda:0'),\n",
       "  2,\n",
       "  50.0,\n",
       "  tensor([2.4490e+03, 2.0000e+00]),\n",
       "  False),\n",
       " (tensor([2500.0000,   82.2844], device='cuda:0'),\n",
       "  2,\n",
       "  60.0,\n",
       "  tensor([2.4300e+03, 2.0000e+00]),\n",
       "  False),\n",
       " (tensor([2500.0000,   83.5061], device='cuda:0'),\n",
       "  3,\n",
       "  69.0,\n",
       "  tensor([2459.,    3.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   95.3861], device='cuda:0'),\n",
       "  2,\n",
       "  22.0,\n",
       "  tensor([2.4840e+03, 2.0000e+00]),\n",
       "  False),\n",
       " (tensor([2500.0000,   99.2208], device='cuda:0'),\n",
       "  0,\n",
       "  0.0,\n",
       "  tensor([2420.,    0.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   27.0147], device='cuda:0'),\n",
       "  0,\n",
       "  0.0,\n",
       "  tensor([2474.,    0.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   82.1814], device='cuda:0'),\n",
       "  0,\n",
       "  0.0,\n",
       "  tensor([2483.,    0.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   67.8755], device='cuda:0'),\n",
       "  3,\n",
       "  63.0,\n",
       "  tensor([2447.,    3.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   43.0081], device='cuda:0'),\n",
       "  2,\n",
       "  86.0,\n",
       "  tensor([2.4130e+03, 2.0000e+00]),\n",
       "  False),\n",
       " (tensor([2500.0000,   12.1317], device='cuda:0'),\n",
       "  2,\n",
       "  8.0,\n",
       "  tensor([2.4920e+03, 2.0000e+00]),\n",
       "  False),\n",
       " (tensor([2500.0000,   63.4702], device='cuda:0'),\n",
       "  0,\n",
       "  0.0,\n",
       "  tensor([2462.,    0.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   28.2678], device='cuda:0'),\n",
       "  2,\n",
       "  50.0,\n",
       "  tensor([2.4560e+03, 2.0000e+00]),\n",
       "  False),\n",
       " (tensor([2500.0000,   82.8994], device='cuda:0'),\n",
       "  0,\n",
       "  0.0,\n",
       "  tensor([2436.,    0.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   88.5948], device='cuda:0'),\n",
       "  0,\n",
       "  0.0,\n",
       "  tensor([2472.,    0.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   69.4035], device='cuda:0'),\n",
       "  3,\n",
       "  120.0,\n",
       "  tensor([2422.,    3.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   87.2021], device='cuda:0'),\n",
       "  0,\n",
       "  0.0,\n",
       "  tensor([2414.,    0.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   90.3814], device='cuda:0'),\n",
       "  3,\n",
       "  27.0,\n",
       "  tensor([2478.,    3.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   56.5147], device='cuda:0'),\n",
       "  2,\n",
       "  32.0,\n",
       "  tensor([2.4580e+03, 2.0000e+00]),\n",
       "  False),\n",
       " (tensor([2500.0000,   87.8633], device='cuda:0'),\n",
       "  1,\n",
       "  36.0,\n",
       "  tensor([2.4250e+03, 1.0000e+00]),\n",
       "  False),\n",
       " (tensor([2500.0000,   83.6495], device='cuda:0'),\n",
       "  2,\n",
       "  18.0,\n",
       "  tensor([2.4830e+03, 2.0000e+00]),\n",
       "  False),\n",
       " (tensor([2500.0000,   93.2431], device='cuda:0'),\n",
       "  3,\n",
       "  12.0,\n",
       "  tensor([2491.,    3.]),\n",
       "  False),\n",
       " (tensor([2500.0000,    4.0708], device='cuda:0'),\n",
       "  0,\n",
       "  0.0,\n",
       "  tensor([2471.,    0.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   39.8034], device='cuda:0'),\n",
       "  0,\n",
       "  0.0,\n",
       "  tensor([2440.,    0.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   41.5418], device='cuda:0'),\n",
       "  1,\n",
       "  4.0,\n",
       "  tensor([2.4900e+03, 1.0000e+00]),\n",
       "  False),\n",
       " (tensor([2500.0000,    9.0830], device='cuda:0'),\n",
       "  2,\n",
       "  32.0,\n",
       "  tensor([2.4590e+03, 2.0000e+00]),\n",
       "  False),\n",
       " (tensor([2500.0000,   16.2445], device='cuda:0'),\n",
       "  0,\n",
       "  0.0,\n",
       "  tensor([2491.,    0.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   24.9182], device='cuda:0'),\n",
       "  0,\n",
       "  0.0,\n",
       "  tensor([2454.,    0.]),\n",
       "  False),\n",
       " (tensor([2500.0000,   36.1606], device='cuda:0'),\n",
       "  1,\n",
       "  39.0,\n",
       "  tensor([2.4240e+03, 1.0000e+00]),\n",
       "  False),\n",
       " (tensor([2500.0000,    4.0000], device='cuda:0'),\n",
       "  1,\n",
       "  18.0,\n",
       "  tensor([2.4520e+03, 1.0000e+00]),\n",
       "  False)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2500.0000,   44.0127], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state1_ = marketEnv.reset()\n",
    "state1 = torch.from_numpy(state1_).float().to(device = devid)\n",
    "state1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.7263e+02,  5.0482e+02,  5.2627e+02,  5.4320e+02, -1.7049e+01,\n",
       "        -2.8721e+02,  2.7055e+02, -1.4449e+02,  6.5888e+01, -1.6998e+02,\n",
       "         1.3855e+02,  9.7636e+01,  1.4713e+02, -5.3032e+00, -2.4343e+01,\n",
       "        -2.9656e+00,  1.3266e+02,  2.9187e+02,  3.2470e+02, -1.2648e+02,\n",
       "         1.6125e+02,  2.8317e+01,  1.1781e+02, -3.0612e+02,  2.0932e+02,\n",
       "         2.5163e+02,  1.9913e+02,  1.5835e+02, -1.6365e+02,  1.5549e+02,\n",
       "        -3.4901e+02,  1.2267e+02, -1.7787e+02, -2.0185e+02, -3.1377e+02,\n",
       "        -3.1752e+01, -2.1371e+02,  1.2422e+02, -1.3482e+02, -5.9435e+02,\n",
       "        -2.0493e+02,  2.4408e-01,  5.8703e+01, -1.2842e+02, -5.7260e+01,\n",
       "        -2.3565e+02,  1.0769e+02,  1.2792e+01, -6.3768e+01,  3.2637e+02,\n",
       "        -1.2837e+02, -3.5006e+02,  1.4588e+01, -5.0801e+01,  5.2414e+01,\n",
       "        -1.5324e+00, -5.6725e+01,  4.4175e+02,  4.0968e+02,  2.7317e+02,\n",
       "        -2.8090e+02, -9.8235e+01, -1.9346e+01,  3.4278e+01,  6.0664e+01,\n",
       "        -2.0080e+02,  2.3787e+02, -3.5602e+02,  6.5912e+01,  1.4627e+02,\n",
       "        -4.8961e+02,  5.6286e+00, -2.3538e+01,  1.5821e+02, -2.2502e+02,\n",
       "        -2.3144e+02, -2.3422e+02, -1.9457e+02,  6.4479e+01, -5.9302e+01,\n",
       "        -5.3073e+01,  4.5682e+01,  1.1670e+02,  4.3761e+02, -8.5279e+01,\n",
       "         1.8331e+02, -3.8396e+02, -1.6252e+02, -4.4379e+02,  1.8269e+02,\n",
       "         3.4854e+02,  2.1947e+02, -1.3220e+02,  2.5064e+02, -7.2860e+01,\n",
       "         2.1339e+02, -2.5144e+02,  8.1259e+01,  1.5703e+02, -1.0533e+02,\n",
       "         1.6900e+02], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qval = model(state1)\n",
    "qval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qval_ = qval.data.cpu().numpy()\n",
    "action_ = np.argmax(qval_)\n",
    "action_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.72629791e+02,  5.04819305e+02,  5.26273438e+02,  5.43196533e+02,\n",
       "       -1.70491486e+01, -2.87211792e+02,  2.70553131e+02, -1.44491684e+02,\n",
       "        6.58883667e+01, -1.69984467e+02,  1.38547211e+02,  9.76364670e+01,\n",
       "        1.47126434e+02, -5.30320501e+00, -2.43429089e+01, -2.96556997e+00,\n",
       "        1.32659195e+02,  2.91867401e+02,  3.24700287e+02, -1.26479279e+02,\n",
       "        1.61249084e+02,  2.83165531e+01,  1.17813896e+02, -3.06119232e+02,\n",
       "        2.09320114e+02,  2.51631531e+02,  1.99133682e+02,  1.58354416e+02,\n",
       "       -1.63645950e+02,  1.55486267e+02, -3.49010681e+02,  1.22671738e+02,\n",
       "       -1.77873123e+02, -2.01853577e+02, -3.13765503e+02, -3.17522507e+01,\n",
       "       -2.13712982e+02,  1.24221939e+02, -1.34824585e+02, -5.94351868e+02,\n",
       "       -2.04926987e+02,  2.44082183e-01,  5.87028618e+01, -1.28422897e+02,\n",
       "       -5.72601891e+01, -2.35652206e+02,  1.07688599e+02,  1.27916727e+01,\n",
       "       -6.37681122e+01,  3.26369904e+02, -1.28370132e+02, -3.50063965e+02,\n",
       "        1.45880718e+01, -5.08008766e+01,  5.24135208e+01, -1.53243363e+00,\n",
       "       -5.67249489e+01,  4.41753998e+02,  4.09682373e+02,  2.73173828e+02,\n",
       "       -2.80900909e+02, -9.82350006e+01, -1.93462982e+01,  3.42778168e+01,\n",
       "        6.06642952e+01, -2.00797897e+02,  2.37869553e+02, -3.56017181e+02,\n",
       "        6.59117813e+01,  1.46272247e+02, -4.89613281e+02,  5.62860727e+00,\n",
       "       -2.35383873e+01,  1.58213928e+02, -2.25020233e+02, -2.31438660e+02,\n",
       "       -2.34223465e+02, -1.94571945e+02,  6.44792633e+01, -5.93018188e+01,\n",
       "       -5.30729218e+01,  4.56817970e+01,  1.16702484e+02,  4.37607941e+02,\n",
       "       -8.52794189e+01,  1.83309479e+02, -3.83958099e+02, -1.62515625e+02,\n",
       "       -4.43786469e+02,  1.82687027e+02,  3.48539948e+02,  2.19468246e+02,\n",
       "       -1.32200958e+02,  2.50637314e+02, -7.28601227e+01,  2.13389755e+02,\n",
       "       -2.51439880e+02,  8.12585983e+01,  1.57025818e+02, -1.05327217e+02,\n",
       "        1.69000641e+02], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qval_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a96fb7c19b5b1285db142f1056a0db812d7358549fa55f502278878339f7abb3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
